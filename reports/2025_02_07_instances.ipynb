{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually looking at high-deception instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame, json_normalize\n",
    "from typing import List, Dict, Any, Tuple, Union, Optional\n",
    "\n",
    "LOGS_PATH: str = \"../evaluations/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import load_agent_logs_df, read_jsonl_as_json, load_game_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPT_NAMES: List[str] = [\n",
    "    \"2025-02-01_phi_llama_100_games_v3\",\n",
    "    \"2025-02-01_llama_phi_100_games_v3\",\n",
    "    \"2025-02-01_phi_phi_100_games_v3\",\n",
    "    \"2025-02-01_llama_llama_100_games_v3\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTIONS: List[str] = [\n",
    "    \"Crew: Phi, Imp: Llama\",\n",
    "    \"Crew: Llama, Imp: Phi\",\n",
    "    \"Crew: Phi, Imp: Phi\",\n",
    "    \"Crew: Llama, Imp: Llama\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_logs_paths: List[str] = [\n",
    "    os.path.join(LOGS_PATH, f\"{expt_name}_all_skill_scores.json\") for expt_name in EXPT_NAMES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dfs: List[DataFrame] = []\n",
    "\n",
    "for summary_logs_path in summary_logs_paths:\n",
    "    # read json line by line\n",
    "    summary_logs: List[Dict[str, Any]] = read_jsonl_as_json(summary_logs_path)\n",
    "    summary_df: DataFrame = json_normalize(summary_logs)\n",
    "    # sort by game_index and then step\n",
    "    summary_df = summary_df.sort_values(by=[\"game_index\", \"step\"])\n",
    "    summary_dfs.append(summary_df)\n",
    "    print(f\"Loaded {len(summary_df)} logs from {summary_logs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all summary dfs with a column for the experiment name for each summary df\n",
    "summary_df_all_expts = pd.concat([summary_df.assign(experiment=expt_name) for summary_df, expt_name in zip(summary_dfs, EXPT_NAMES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for high deception and SPEAK actions\n",
    "high_deception_filtered_df = summary_df_all_expts[\n",
    "    (summary_df_all_expts['deception'] == '10') & \n",
    "    (summary_df_all_expts['action'].str.contains('SPEAK', na=False)) &\n",
    "    (summary_df_all_expts['action'].str.contains('a lot of movement', na=False))\n",
    "]\n",
    "\n",
    "high_deception_filtered_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_deception_filtered_df[['thought', 'action']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_deception_filtered_df.loc[2122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reporting 5125 and 2122\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amongus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}