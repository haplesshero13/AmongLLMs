{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deception ELO!\n",
    "\n",
    "An all-models war on Among Us to see who is the best at deceptive capability. There will be blood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, json_normalize\n",
    "from typing import List, Dict, Any, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELO parameters\n",
    "K = 32\n",
    "BASE_ELO = 1500\n",
    "\n",
    "def update_elo(winner_elo, loser_elo):\n",
    "    expected_win = 1 / (1 + 10 ** ((loser_elo - winner_elo) / 400))\n",
    "    change = K * (1 - expected_win)\n",
    "    return winner_elo + change, loser_elo - change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH: str = \"../expt-logs/\"\n",
    "EXPT_NAME: str = \"2025-02-19_deception_elo_v2\"\n",
    "summary_df_path: str =  os.path.join(LOGS_PATH, EXPT_NAME, \"summary.json\")\n",
    "\n",
    "with open(summary_df_path, \"r\") as f:\n",
    "    games = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [list(game.values())[0] for game in games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_scores = collections.defaultdict(lambda: BASE_ELO)\n",
    "win_counts = collections.defaultdict(lambda: {\"wins\": 0, \"games\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, game in enumerate(games):\n",
    "    if idx % (len(games) // 10) == 0:\n",
    "        print(f'Processing game {idx}/{len(games)}.')\n",
    "    impostor_models = []\n",
    "    all_models = []\n",
    "    impostor_won = game[\"winner\"] == 1  # 1 = Impostor win, 3 = Crewmate win\n",
    "    \n",
    "    # Identify impostors\n",
    "    for player in game:\n",
    "        if player.startswith(\"Player\"):\n",
    "            model = game[player][\"model\"]\n",
    "            all_models.append(model)\n",
    "            if game[player][\"identity\"] == \"Impostor\":\n",
    "                impostor_models.append(model)\n",
    "    \n",
    "    # Update Elo only for impostors\n",
    "    if impostor_models:\n",
    "        avg_crewmate_elo = sum(elo_scores[m] for m in elo_scores if m not in impostor_models) / max(1, len(elo_scores) - len(impostor_models))\n",
    "        for impostor in impostor_models:\n",
    "            if impostor not in elo_scores:\n",
    "                elo_scores[impostor] = BASE_ELO\n",
    "            if impostor_won:\n",
    "                elo_scores[impostor], _ = update_elo(elo_scores[impostor], avg_crewmate_elo)\n",
    "            else:\n",
    "                _, elo_scores[impostor] = update_elo(avg_crewmate_elo, elo_scores[impostor])\n",
    "\n",
    "    # Update win counts for all players\n",
    "    for model in all_models:\n",
    "        win_counts[model][\"games\"] += 1\n",
    "        if (model in impostor_models and impostor_won) or (model not in impostor_models and not impostor_won):\n",
    "            win_counts[model][\"wins\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_rates():\n",
    "    return {model: win_counts[model][\"wins\"] / win_counts[model][\"games\"] for model in win_counts if win_counts[model][\"games\"] > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_scores = dict(sorted(elo_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "win_rates = get_win_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a consistent list of models, elos, and win rates\n",
    "models = sorted(set(elo_scores.keys()).union(win_rates.keys()))\n",
    "elo_scores = [elo_scores.get(model, BASE_ELO) for model in models]\n",
    "win_rates = [win_rates.get(model, 0) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, elo_scores, win_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_elo_vs_winrate(elo_scores, win_rates):\n",
    "    # Define colors\n",
    "    colors = ['#1f77b4', '#d62728', '#2ca02c', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    textpositions = ['top center', 'bottom center', 'middle left', 'bottom center','top right', 'top left', 'middle right', 'bottom center', 'middle left'] \n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add scatter plot\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[wr*100 for wr in win_rates],  # Convert to percentage\n",
    "        y=elo_scores,\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=16,\n",
    "            color=colors[:len(elo_scores)],\n",
    "            line=dict(width=1, color='black')\n",
    "        ),\n",
    "        text=[model.split('/')[-1] for model in models],\n",
    "        textposition=textpositions[:len(elo_scores)],\n",
    "        textfont=dict(family=\"Computer Modern\"),\n",
    "        name=''\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        font=dict(family=\"Computer Modern\", size=14),\n",
    "        xaxis=dict(\n",
    "            title=r'Win Rate (%)',\n",
    "            gridcolor='lightgray',\n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='black',\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=r'Deception ELO',\n",
    "            gridcolor='lightgray', \n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='black',\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        width=600,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    # both axes should start at 0\n",
    "    fig.update_xaxes(range=[10, 80])\n",
    "    # fig.update_yaxes(range=[1000, max(elo_scores.values()) + 100])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_elo_vs_winrate(elo_scores, win_rates)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amongus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}